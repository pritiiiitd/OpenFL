{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q2qSoIK8bm4Y",
        "outputId": "711fc460-4fc7-4e1d-a539-ef925ddb30e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow==2.7.0\n",
            "  Downloading tensorflow-2.7.0-cp38-cp38-manylinux2010_x86_64.whl (489.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m489.6/489.6 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.7.0) (1.6.3)\n",
            "Collecting keras<2.8,>=2.7.0rc0\n",
            "  Downloading keras-2.7.0-py2.py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wheel<1.0,>=0.32.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.7.0) (0.38.4)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.7.0) (1.14.1)\n",
            "Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.7.0) (2.9.1)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.7.0) (1.15.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.7.0) (1.51.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.7.0) (4.4.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.7.0) (0.29.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.7.0) (14.0.6)\n",
            "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.7.0) (1.12)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.7.0) (3.3.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.7.0) (3.19.6)\n",
            "Requirement already satisfied: gast<0.5.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.7.0) (0.4.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.7.0) (1.1.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.7.0) (2.2.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.7.0) (1.3.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.7.0) (3.1.0)\n",
            "Collecting tensorflow-estimator<2.8,~=2.7.0rc0\n",
            "  Downloading tensorflow_estimator-2.7.0-py2.py3-none-any.whl (463 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m463.1/463.1 KB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.7.0) (0.2.0)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.7.0) (1.21.6)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0) (1.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0) (2.25.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0) (2.15.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0) (1.8.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0) (57.4.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0) (0.6.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0) (3.4.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0) (0.4.6)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.7.0) (4.9)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.7.0) (5.2.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.7.0) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow==2.7.0) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow==2.7.0) (6.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.7.0) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.7.0) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.7.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.7.0) (4.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow==2.7.0) (3.11.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.7.0) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow==2.7.0) (3.2.2)\n",
            "Installing collected packages: tensorflow-estimator, keras, tensorflow\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.9.0\n",
            "    Uninstalling tensorflow-estimator-2.9.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.9.0\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.9.0\n",
            "    Uninstalling keras-2.9.0:\n",
            "      Successfully uninstalled keras-2.9.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.9.2\n",
            "    Uninstalling tensorflow-2.9.2:\n",
            "      Successfully uninstalled tensorflow-2.9.2\n",
            "Successfully installed keras-2.7.0 tensorflow-2.7.0 tensorflow-estimator-2.7.0\n"
          ]
        }
      ],
      "source": [
        "#Install Tensorflow and MNIST dataset if not installed\n",
        "!pip install tensorflow==2.7.0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openfl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lXRyYY3pcT78",
        "outputId": "b9514287-b912-47f7-dae1-138543c235eb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting openfl\n",
            "  Downloading openfl-1.4-py3-none-any.whl (612 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m612.5/612.5 KB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorboardX\n",
            "  Downloading tensorboardX-2.5.1-py2.py3-none-any.whl (125 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.4/125.4 KB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from openfl) (1.3.5)\n",
            "Collecting jupyterlab\n",
            "  Downloading jupyterlab-3.5.2-py3-none-any.whl (8.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m69.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting protobuf==3.19.4\n",
            "  Downloading protobuf-3.19.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m57.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cloudpickle in /usr/local/lib/python3.8/dist-packages (from openfl) (2.2.0)\n",
            "Collecting Click==8.0.1\n",
            "  Downloading click-8.0.1-py3-none-any.whl (97 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.4/97.4 KB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from openfl) (4.64.1)\n",
            "Collecting rich\n",
            "  Downloading rich-13.1.0-py3-none-any.whl (238 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m238.4/238.4 KB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from openfl) (2.25.1)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.8/dist-packages (from openfl) (5.3.4)\n",
            "Requirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.8/dist-packages (from openfl) (6.0)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.8/dist-packages (from openfl) (2.9.1)\n",
            "Collecting dynaconf==3.1.7\n",
            "  Downloading dynaconf-3.1.7-py2.py3-none-any.whl (200 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.6/200.6 KB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (from openfl) (1.0.2)\n",
            "Collecting grpcio~=1.34.0\n",
            "  Downloading grpcio-1.34.1-cp38-cp38-manylinux2014_x86_64.whl (4.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m57.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from openfl) (1.21.6)\n",
            "Collecting cryptography>=3.4.6\n",
            "  Downloading cryptography-39.0.0-cp36-abi3-manylinux_2_24_x86_64.whl (4.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.1/4.1 MB\u001b[0m \u001b[31m52.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting flatten-json\n",
            "  Downloading flatten_json-0.1.13.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting docker\n",
            "  Downloading docker-6.0.1-py3-none-any.whl (147 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.5/147.5 KB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.8/dist-packages (from cryptography>=3.4.6->openfl) (1.15.1)\n",
            "Requirement already satisfied: six>=1.5.2 in /usr/local/lib/python3.8/dist-packages (from grpcio~=1.34.0->openfl) (1.15.0)\n",
            "Collecting requests\n",
            "  Downloading requests-2.28.2-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 KB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=14.0 in /usr/local/lib/python3.8/dist-packages (from docker->openfl) (21.3)\n",
            "Collecting websocket-client>=0.32.0\n",
            "  Downloading websocket_client-1.4.2-py3-none-any.whl (55 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.3/55.3 KB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting urllib3>=1.26.0\n",
            "  Downloading urllib3-1.26.14-py2.py3-none-any.whl (140 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.6/140.6 KB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/dist-packages (from requests->openfl) (2.1.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->openfl) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->openfl) (2.10)\n",
            "Requirement already satisfied: traitlets>=4.1.0 in /usr/local/lib/python3.8/dist-packages (from ipykernel->openfl) (5.7.1)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.8/dist-packages (from ipykernel->openfl) (6.1.12)\n",
            "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.8/dist-packages (from ipykernel->openfl) (6.0.4)\n",
            "Requirement already satisfied: ipython>=5.0.0 in /usr/local/lib/python3.8/dist-packages (from ipykernel->openfl) (7.9.0)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.8/dist-packages (from jupyterlab->openfl) (5.1.2)\n",
            "Collecting jupyterlab-server~=2.10\n",
            "  Downloading jupyterlab_server-2.19.0-py3-none-any.whl (56 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.4/56.4 KB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tomli in /usr/local/lib/python3.8/dist-packages (from jupyterlab->openfl) (2.0.1)\n",
            "Collecting nbclassic\n",
            "  Downloading nbclassic-0.4.8-py3-none-any.whl (9.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.8/9.8 MB\u001b[0m \u001b[31m91.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tornado>=4.2\n",
            "  Downloading tornado-6.2-cp37-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (423 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m424.0/424.0 KB\u001b[0m \u001b[31m36.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jupyter-server<3,>=1.16.0\n",
            "  Downloading jupyter_server-2.1.0-py3-none-any.whl (365 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m365.2/365.2 KB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: notebook<7 in /usr/local/lib/python3.8/dist-packages (from jupyterlab->openfl) (5.7.16)\n",
            "Requirement already satisfied: jinja2>=2.1 in /usr/local/lib/python3.8/dist-packages (from jupyterlab->openfl) (2.11.3)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->openfl) (2022.7)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->openfl) (2.8.2)\n",
            "Collecting commonmark<0.10.0,>=0.9.0\n",
            "  Downloading commonmark-0.9.1-py2.py3-none-any.whl (51 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.1/51.1 KB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions<5.0,>=4.0.0 in /usr/local/lib/python3.8/dist-packages (from rich->openfl) (4.4.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.6.0 in /usr/local/lib/python3.8/dist-packages (from rich->openfl) (2.6.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->openfl) (3.1.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->openfl) (1.7.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->openfl) (1.2.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.8/dist-packages (from tensorboard->openfl) (1.3.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard->openfl) (0.6.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard->openfl) (0.4.6)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard->openfl) (2.15.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard->openfl) (57.4.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.8/dist-packages (from tensorboard->openfl) (0.38.4)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard->openfl) (1.8.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard->openfl) (3.4.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard->openfl) (1.0.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.8/dist-packages (from cffi>=1.12->cryptography>=3.4.6->openfl) (2.21)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard->openfl) (5.2.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard->openfl) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard->openfl) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->openfl) (1.3.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.8/dist-packages (from ipython>=5.0.0->ipykernel->openfl) (0.2.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from ipython>=5.0.0->ipykernel->openfl) (2.0.10)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.8/dist-packages (from ipython>=5.0.0->ipykernel->openfl) (4.8.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.8/dist-packages (from ipython>=5.0.0->ipykernel->openfl) (0.7.5)\n",
            "Collecting jedi>=0.10\n",
            "  Downloading jedi-0.18.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m57.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.8/dist-packages (from ipython>=5.0.0->ipykernel->openfl) (4.4.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from jinja2>=2.1->jupyterlab->openfl) (2.0.1)\n",
            "Collecting jupyter-server-terminals\n",
            "  Downloading jupyter_server_terminals-0.4.4-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: nbformat>=5.3.0 in /usr/local/lib/python3.8/dist-packages (from jupyter-server<3,>=1.16.0->jupyterlab->openfl) (5.7.1)\n",
            "Collecting argon2-cffi\n",
            "  Downloading argon2_cffi-21.3.0-py3-none-any.whl (14 kB)\n",
            "Collecting jupyter-events>=0.4.0\n",
            "  Downloading jupyter_events-0.6.3-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: send2trash in /usr/local/lib/python3.8/dist-packages (from jupyter-server<3,>=1.16.0->jupyterlab->openfl) (1.8.0)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.8/dist-packages (from jupyter-server<3,>=1.16.0->jupyterlab->openfl) (0.13.3)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.8/dist-packages (from jupyter-server<3,>=1.16.0->jupyterlab->openfl) (0.15.0)\n",
            "Collecting pyzmq>=24\n",
            "  Downloading pyzmq-25.0.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m59.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nbconvert>=6.4.4\n",
            "  Downloading nbconvert-7.2.8-py3-none-any.whl (274 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m274.8/274.8 KB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting anyio<4,>=3.1.0\n",
            "  Downloading anyio-3.6.2-py3-none-any.whl (80 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.6/80.6 KB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jupyter-client\n",
            "  Downloading jupyter_client-7.4.9-py3-none-any.whl (133 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.5/133.5 KB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: entrypoints in /usr/local/lib/python3.8/dist-packages (from jupyter-client->ipykernel->openfl) (0.4)\n",
            "Collecting nest-asyncio>=1.5.4\n",
            "  Downloading nest_asyncio-1.5.6-py3-none-any.whl (5.2 kB)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.8/dist-packages (from jupyter-core->jupyterlab->openfl) (2.6.2)\n",
            "Collecting jinja2>=2.1\n",
            "  Downloading Jinja2-3.1.2-py3-none-any.whl (133 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.1/133.1 KB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: babel>=2.10 in /usr/local/lib/python3.8/dist-packages (from jupyterlab-server~=2.10->jupyterlab->openfl) (2.11.0)\n",
            "Collecting json5>=0.9.0\n",
            "  Downloading json5-0.9.11-py2.py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: importlib-metadata>=4.8.3 in /usr/local/lib/python3.8/dist-packages (from jupyterlab-server~=2.10->jupyterlab->openfl) (6.0.0)\n",
            "Collecting jsonschema>=4.17.3\n",
            "  Downloading jsonschema-4.17.3-py3-none-any.whl (90 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.4/90.4 KB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting notebook<7\n",
            "  Downloading notebook-6.5.2-py3-none-any.whl (439 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m439.1/439.1 KB\u001b[0m \u001b[31m34.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: ipython-genutils in /usr/local/lib/python3.8/dist-packages (from notebook<7->jupyterlab->openfl) (0.2.0)\n",
            "Collecting notebook-shim>=0.1.0\n",
            "  Downloading notebook_shim-0.2.2-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=14.0->docker->openfl) (3.0.9)\n",
            "Collecting sniffio>=1.1\n",
            "  Downloading sniffio-1.3.0-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.8.3->jupyterlab-server~=2.10->jupyterlab->openfl) (3.11.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.8/dist-packages (from jedi>=0.10->ipython>=5.0.0->ipykernel->openfl) (0.8.3)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>=4.17.3->jupyterlab-server~=2.10->jupyterlab->openfl) (5.10.2)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>=4.17.3->jupyterlab-server~=2.10->jupyterlab->openfl) (22.2.0)\n",
            "Collecting pkgutil-resolve-name>=1.3.10\n",
            "  Downloading pkgutil_resolve_name-1.3.10-py3-none-any.whl (4.7 kB)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>=4.17.3->jupyterlab-server~=2.10->jupyterlab->openfl) (0.19.3)\n",
            "Requirement already satisfied: jsonschema[format-nongpl]>=3.2.0 in /usr/local/lib/python3.8/dist-packages (from jupyter-events>=0.4.0->jupyter-server<3,>=1.16.0->jupyterlab->openfl) (4.3.3)\n",
            "Collecting rfc3339-validator\n",
            "  Downloading rfc3339_validator-0.1.4-py2.py3-none-any.whl (3.5 kB)\n",
            "Collecting python-json-logger>=2.0.4\n",
            "  Downloading python_json_logger-2.0.4-py3-none-any.whl (7.8 kB)\n",
            "Collecting rfc3986-validator>=0.1.1\n",
            "  Downloading rfc3986_validator-0.1.1-py2.py3-none-any.whl (4.2 kB)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.8/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=1.16.0->jupyterlab->openfl) (0.7.1)\n",
            "Collecting nbclient>=0.5.0\n",
            "  Downloading nbclient-0.7.2-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 KB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tinycss2\n",
            "  Downloading tinycss2-1.2.1-py3-none-any.whl (21 kB)\n",
            "Collecting jupyterlab-pygments\n",
            "  Downloading jupyterlab_pygments-0.2.2-py2.py3-none-any.whl (21 kB)\n",
            "Collecting mistune<3,>=2.0.3\n",
            "  Downloading mistune-2.0.4-py2.py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.8/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=1.16.0->jupyterlab->openfl) (1.5.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.8/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=1.16.0->jupyterlab->openfl) (4.6.3)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.8/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=1.16.0->jupyterlab->openfl) (5.0.1)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.8/dist-packages (from nbformat>=5.3.0->jupyter-server<3,>=1.16.0->jupyterlab->openfl) (2.16.2)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.8/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython>=5.0.0->ipykernel->openfl) (0.2.5)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->openfl) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->openfl) (3.2.2)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.8/dist-packages (from terminado>=0.8.3->jupyter-server<3,>=1.16.0->jupyterlab->openfl) (0.7.0)\n",
            "Collecting argon2-cffi-bindings\n",
            "  Downloading argon2_cffi_bindings-21.2.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.2/86.2 KB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[33mWARNING: jsonschema 4.3.3 does not provide the extra 'format-nongpl'\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting webcolors>=1.11\n",
            "  Downloading webcolors-1.12-py3-none-any.whl (9.9 kB)\n",
            "Collecting isoduration\n",
            "  Downloading isoduration-20.11.0-py3-none-any.whl (11 kB)\n",
            "Collecting jsonpointer>1.13\n",
            "  Downloading jsonpointer-2.3-py2.py3-none-any.whl (7.8 kB)\n",
            "Collecting fqdn\n",
            "  Downloading fqdn-1.5.1-py3-none-any.whl (9.1 kB)\n",
            "Collecting uri-template\n",
            "  Downloading uri_template-1.2.0-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.8/dist-packages (from bleach->nbconvert>=6.4.4->jupyter-server<3,>=1.16.0->jupyterlab->openfl) (0.5.1)\n",
            "Collecting arrow>=0.15.0\n",
            "  Downloading arrow-1.2.3-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.4/66.4 KB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: flatten-json\n",
            "  Building wheel for flatten-json (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for flatten-json: filename=flatten_json-0.1.13-py3-none-any.whl size=7978 sha256=cb644172dc110d9c874b8527e8e4b6c28afc804b030603f26181a1828b25ba87\n",
            "  Stored in directory: /root/.cache/pip/wheels/87/c5/6d/7a772fecd8d6ebae9e60d997f74b9a96ead7d5a0f26a920090\n",
            "Successfully built flatten-json\n",
            "Installing collected packages: mistune, json5, commonmark, websocket-client, webcolors, urllib3, uri-template, tornado, tinycss2, sniffio, rich, rfc3986-validator, rfc3339-validator, pyzmq, python-json-logger, protobuf, pkgutil-resolve-name, nest-asyncio, jupyterlab-pygments, jsonpointer, jinja2, jedi, grpcio, fqdn, flatten-json, dynaconf, Click, tensorboardX, requests, jupyter-client, jsonschema, cryptography, arrow, argon2-cffi-bindings, anyio, jupyter-server-terminals, isoduration, docker, argon2-cffi, nbclient, nbconvert, jupyter-events, jupyter-server, notebook-shim, jupyterlab-server, nbclassic, notebook, jupyterlab, openfl\n",
            "  Attempting uninstall: mistune\n",
            "    Found existing installation: mistune 0.8.4\n",
            "    Uninstalling mistune-0.8.4:\n",
            "      Successfully uninstalled mistune-0.8.4\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: tornado\n",
            "    Found existing installation: tornado 6.0.4\n",
            "    Uninstalling tornado-6.0.4:\n",
            "      Successfully uninstalled tornado-6.0.4\n",
            "  Attempting uninstall: pyzmq\n",
            "    Found existing installation: pyzmq 23.2.1\n",
            "    Uninstalling pyzmq-23.2.1:\n",
            "      Successfully uninstalled pyzmq-23.2.1\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.19.6\n",
            "    Uninstalling protobuf-3.19.6:\n",
            "      Successfully uninstalled protobuf-3.19.6\n",
            "  Attempting uninstall: jinja2\n",
            "    Found existing installation: Jinja2 2.11.3\n",
            "    Uninstalling Jinja2-2.11.3:\n",
            "      Successfully uninstalled Jinja2-2.11.3\n",
            "  Attempting uninstall: grpcio\n",
            "    Found existing installation: grpcio 1.51.1\n",
            "    Uninstalling grpcio-1.51.1:\n",
            "      Successfully uninstalled grpcio-1.51.1\n",
            "  Attempting uninstall: Click\n",
            "    Found existing installation: click 7.1.2\n",
            "    Uninstalling click-7.1.2:\n",
            "      Successfully uninstalled click-7.1.2\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.25.1\n",
            "    Uninstalling requests-2.25.1:\n",
            "      Successfully uninstalled requests-2.25.1\n",
            "  Attempting uninstall: jupyter-client\n",
            "    Found existing installation: jupyter-client 6.1.12\n",
            "    Uninstalling jupyter-client-6.1.12:\n",
            "      Successfully uninstalled jupyter-client-6.1.12\n",
            "  Attempting uninstall: jsonschema\n",
            "    Found existing installation: jsonschema 4.3.3\n",
            "    Uninstalling jsonschema-4.3.3:\n",
            "      Successfully uninstalled jsonschema-4.3.3\n",
            "  Attempting uninstall: nbconvert\n",
            "    Found existing installation: nbconvert 5.6.1\n",
            "    Uninstalling nbconvert-5.6.1:\n",
            "      Successfully uninstalled nbconvert-5.6.1\n",
            "  Attempting uninstall: notebook\n",
            "    Found existing installation: notebook 5.7.16\n",
            "    Uninstalling notebook-5.7.16:\n",
            "      Successfully uninstalled notebook-5.7.16\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "grpcio-status 1.48.2 requires grpcio>=1.48.2, but you have grpcio 1.34.1 which is incompatible.\n",
            "googleapis-common-protos 1.57.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.19.4 which is incompatible.\n",
            "google-colab 1.0.0 requires notebook~=5.7.16, but you have notebook 6.5.2 which is incompatible.\n",
            "google-colab 1.0.0 requires tornado~=6.0.4, but you have tornado 6.2 which is incompatible.\n",
            "google-cloud-translate 3.8.4 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.19.4 which is incompatible.\n",
            "google-cloud-language 2.6.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.19.4 which is incompatible.\n",
            "google-cloud-firestore 2.7.3 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.19.4 which is incompatible.\n",
            "google-cloud-datastore 2.11.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.19.4 which is incompatible.\n",
            "google-cloud-bigquery 3.4.1 requires grpcio<2.0dev,>=1.47.0, but you have grpcio 1.34.1 which is incompatible.\n",
            "google-cloud-bigquery 3.4.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.19.4 which is incompatible.\n",
            "google-cloud-bigquery-storage 2.17.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.19.4 which is incompatible.\n",
            "google-api-core 2.11.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.19.4 which is incompatible.\n",
            "flask 1.1.4 requires click<8.0,>=5.1, but you have click 8.0.1 which is incompatible.\n",
            "flask 1.1.4 requires Jinja2<3.0,>=2.10.1, but you have jinja2 3.1.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Click-8.0.1 anyio-3.6.2 argon2-cffi-21.3.0 argon2-cffi-bindings-21.2.0 arrow-1.2.3 commonmark-0.9.1 cryptography-39.0.0 docker-6.0.1 dynaconf-3.1.7 flatten-json-0.1.13 fqdn-1.5.1 grpcio-1.34.1 isoduration-20.11.0 jedi-0.18.2 jinja2-3.1.2 json5-0.9.11 jsonpointer-2.3 jsonschema-4.17.3 jupyter-client-7.4.9 jupyter-events-0.6.3 jupyter-server-2.1.0 jupyter-server-terminals-0.4.4 jupyterlab-3.5.2 jupyterlab-pygments-0.2.2 jupyterlab-server-2.19.0 mistune-2.0.4 nbclassic-0.4.8 nbclient-0.7.2 nbconvert-7.2.8 nest-asyncio-1.5.6 notebook-6.5.2 notebook-shim-0.2.2 openfl-1.4 pkgutil-resolve-name-1.3.10 protobuf-3.19.4 python-json-logger-2.0.4 pyzmq-25.0.0 requests-2.28.2 rfc3339-validator-0.1.4 rfc3986-validator-0.1.1 rich-13.1.0 sniffio-1.3.0 tensorboardX-2.5.1 tinycss2-1.2.1 tornado-6.2 uri-template-1.2.0 urllib3-1.26.14 webcolors-1.12 websocket-client-1.4.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, Flatten, Dense, MaxPool2D\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "import openfl.native as fx\n",
        "from openfl.federated import FederatedModel,FederatedDataSet\n",
        "tf.config.run_functions_eagerly(True)\n",
        "tf.random.set_seed(0)\n",
        "np.random.seed(0)"
      ],
      "metadata": {
        "id": "OFT-3zsHcjBy"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_intel_tensorflow():\n",
        "    \"\"\"\n",
        "    Check if Intel version of TensorFlow is installed\n",
        "    \"\"\"\n",
        "    import tensorflow as tf\n",
        "\n",
        "    print(\"We are using Tensorflow version {}\".format(tf.__version__))\n",
        "\n",
        "    major_version = int(tf.__version__.split(\".\")[0])\n",
        "    if major_version >= 2:\n",
        "        from tensorflow.python.util import _pywrap_util_port\n",
        "        print(\"Intel-optimizations (DNNL) enabled:\",\n",
        "              _pywrap_util_port.IsMklEnabled())\n",
        "    else:\n",
        "        print(\"Intel-optimizations (DNNL) enabled:\")\n",
        "\n",
        "test_intel_tensorflow()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zGJYnnihcnmp",
        "outputId": "262289df-5bea-47c0-fe39-7f33c6f7648d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "We are using Tensorflow version 2.7.0\n",
            "Intel-optimizations (DNNL) enabled: False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Setup default workspace, logging, etc.\n",
        "fx.init('keras_cnn_mnist')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b8jyCxLOcr-F",
        "outputId": "a39bb098-1c19-488d-ae98-695089d98843"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating Workspace Directories\n",
            "Creating Workspace Templates\n",
            "Successfully installed packages from /root/.local/workspace/requirements.txt.\n",
            "\n",
            "New workspace directory structure:\n",
            "workspace\n",
            "├── save\n",
            "├── src\n",
            "│   ├── keras_cnn.py\n",
            "│   ├── mnist_utils.py\n",
            "│   ├── tfmnist_inmemory.py\n",
            "│   └── __init__.py\n",
            "├── .workspace\n",
            "├── plan\n",
            "│   ├── data.yaml\n",
            "│   ├── cols.yaml\n",
            "│   ├── defaults\n",
            "│   └── plan.yaml\n",
            "├── cert\n",
            "├── requirements.txt\n",
            "├── logs\n",
            "└── data\n",
            "\n",
            "6 directories, 10 files\n",
            "Setting Up Certificate Authority...\n",
            "\n",
            "1.  Create Root CA\n",
            "1.1 Create Directories\n",
            "1.2 Create Database\n",
            "1.3 Create CA Request and Certificate\n",
            "2.  Create Signing Certificate\n",
            "2.1 Create Directories\n",
            "2.2 Create Database\n",
            "2.3 Create Signing Certificate CSR\n",
            "2.4 Sign Signing Certificate CSR\n",
            "3   Create Certificate Chain\n",
            "\n",
            "Done.\n",
            "Creating AGGREGATOR certificate key pair with following settings: CN=\u001b[31me2498b5a2b64\u001b[0m, SAN=\u001b[31mDNS:e2498b5a2b64\u001b[0m\n",
            "  Writing AGGREGATOR certificate key pair to: \u001b[32m/content/cert/server\u001b[0m\n",
            "The CSR Hash for file \u001b[32mserver/agg_e2498b5a2b64.csr\u001b[0m = \u001b[31m132c3349340a47021b315df2af848900bcf214253ef9748492f5cfe89275479e470b9f71d4b1be00c5fd4622895115bb\u001b[0m\n",
            " Signing AGGREGATOR certificate\n",
            "Creating COLLABORATOR certificate key pair with following settings: CN=\u001b[31mone\u001b[0m, SAN=\u001b[31mDNS:one\u001b[0m\n",
            "  Moving COLLABORATOR certificate to: \u001b[32m/content/cert/col_one\u001b[0m\n",
            "The CSR Hash for file \u001b[32mcol_one.csr\u001b[0m = \u001b[31md818beb7914797b3d517b23cc80ff3982e5884aa6c96cf2672c6cd4915edadb4ec08474f56db216f5b76530b26766ad3\u001b[0m\n",
            " Signing COLLABORATOR certificate\n",
            "\n",
            "Registering \u001b[32mone\u001b[0m in \u001b[32m/root/.local/workspace/plan/cols.yaml\u001b[0m\n",
            "Creating COLLABORATOR certificate key pair with following settings: CN=\u001b[31mtwo\u001b[0m, SAN=\u001b[31mDNS:two\u001b[0m\n",
            "  Moving COLLABORATOR certificate to: \u001b[32m/content/cert/col_two\u001b[0m\n",
            "The CSR Hash for file \u001b[32mcol_two.csr\u001b[0m = \u001b[31me9838273bddc5353ebc6835cc45ae64c3f2423a702d4b5085db403360442dd9ec181f660b7f79996915f0bd79bb14401\u001b[0m\n",
            " Signing COLLABORATOR certificate\n",
            "\n",
            "Registering \u001b[32mtwo\u001b[0m in \u001b[32m/root/.local/workspace/plan/cols.yaml\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Import and process training, validation, and test images/labels\n",
        "\n",
        "# Set the ratio of validation imgs, can't be 0.0\n",
        "VALID_PERCENT = 0.3\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "split_on = int((1 - VALID_PERCENT) * len(X_train))\n",
        "\n",
        "train_images = X_train[0:split_on,:,:]\n",
        "train_labels = to_categorical(y_train)[0:split_on,:]\n",
        "\n",
        "valid_images = X_train[split_on:,:,:]\n",
        "valid_labels = to_categorical(y_train)[split_on:,:]\n",
        "\n",
        "test_images = X_test\n",
        "test_labels = to_categorical(y_test)\n",
        "\n",
        "def preprocess(images):\n",
        "    #Normalize\n",
        "    images = (images / 255) - 0.5\n",
        "    images = images.reshape(images.shape[0], -1)\n",
        "#     images = np.expand_dims(images, axis=-1)\n",
        "    return images\n",
        "\n",
        "# Preprocess the images.\n",
        "train_images = preprocess(train_images)\n",
        "valid_images = preprocess(valid_images)\n",
        "test_images = preprocess(test_images)\n",
        "\n",
        "feature_shape = train_images.shape[1:]\n",
        "classes = 10\n",
        "\n",
        "class UnbalancedFederatedDataset(FederatedDataSet):\n",
        "    def split(self, num_collaborators, shuffle=True, equally=False):\n",
        "        train_idx = self.split_lognormal(self.y_train, num_collaborators)\n",
        "        X_train = np.array([self.X_train[idx] for idx in train_idx])\n",
        "        y_train = np.array([self.y_train[idx] for idx in train_idx])\n",
        "        \n",
        "        valid_idx = self.split_lognormal(self.y_valid, num_collaborators)\n",
        "        X_valid = np.array([self.X_valid[idx] for idx in valid_idx])\n",
        "        y_valid = np.array([self.y_valid[idx] for idx in valid_idx])\n",
        "        \n",
        "        return [\n",
        "            FederatedDataSet(\n",
        "                X_train[i],\n",
        "                y_train[i],\n",
        "                X_valid[i],\n",
        "                y_valid[i],\n",
        "                batch_size=self.batch_size,\n",
        "                num_classes=self.num_classes\n",
        "            ) for i in range(num_collaborators)\n",
        "        ]\n",
        "    \n",
        "    def split_lognormal(self, labels, num_collaborators):\n",
        "        from tqdm import trange\n",
        "        labels = np.argmax(labels, axis=1)\n",
        "        idx = [[np.nonzero(labels == (col + j) % self.num_classes)[0][np.arange(5) + (col // 10 * 10 + 5 * j)] \\\n",
        "            for j in range(2)] for col in range(num_collaborators)]\n",
        "        idx = [np.hstack(tup) for tup in idx]\n",
        "        assert all([len(i) == 10 for i in idx]), 'All collaborators should have 10 elements at this stage'\n",
        "        props = np.random.lognormal(0, 2.0, (10,100,2))\n",
        "        props = np.array([[[len(np.nonzero(labels==label)[0])-1000]] for label in range(10)])*props/np.sum(props,(1,2), keepdims=True)\n",
        "        #idx = 1000*np.ones(10, dtype=np.int64)\n",
        "        for user in trange(1000):\n",
        "            for j in range(2):\n",
        "                l = (user+j)%10\n",
        "                num_samples = int(props[l,user//10,j])\n",
        "                if np.count_nonzero(labels[np.hstack(idx)] == l) + num_samples < len(np.nonzero(labels==l)[0]):\n",
        "                    idx_to_append = np.nonzero(labels == (user + j) % 10)[0][np.arange(num_samples) + np.count_nonzero(labels[np.hstack(idx)] == l)]\n",
        "                    idx[user] = np.append(idx[user], idx_to_append)\n",
        "        return idx\n",
        "\n",
        "fl_data = UnbalancedFederatedDataset(train_images,train_labels,valid_images,valid_labels,batch_size=32,num_classes=classes)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "19sWl5Ojdb5F",
        "outputId": "b184a7c3-377d-4213-ec8e-9ec984d26794"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 1s 0us/step\n",
            "11501568/11490434 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from openfl.utilities.optimizers.keras import FedProxOptimizer"
      ],
      "metadata": {
        "id": "uHYwF1PPdg4r"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(input_shape,\n",
        "                num_classes,\n",
        "                **kwargs):\n",
        "    \"\"\"\n",
        "    Define the model architecture.\n",
        "\n",
        "    Args:\n",
        "        input_shape (numpy.ndarray): The shape of the data\n",
        "        num_classes (int): The number of classes of the dataset\n",
        "\n",
        "    Returns:\n",
        "        tensorflow.python.keras.engine.sequential.Sequential: The model defined in Keras\n",
        "\n",
        "    \"\"\"\n",
        "    model = Sequential()\n",
        "    \n",
        "    model.add(tf.keras.Input(shape=input_shape))\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "                  optimizer=FedProxOptimizer(mu=1),\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model   \n"
      ],
      "metadata": {
        "id": "GKg6AgUWdlc0"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a federated model using the build model function and dataset\n",
        "fl_model = FederatedModel(build_model, data_loader=fl_data)"
      ],
      "metadata": {
        "id": "SLAewRlHdpqn"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "collaborator_models = fl_model.setup(num_collaborators=1000)\n",
        " \n",
        "collaborators = {f'col{col}':collaborator_models[col] for col in range(len(collaborator_models))}#, 'three':collaborator_models[2]}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iUzf_6NSds8p",
        "outputId": "072f1348-0836-4e3d-ebb9-69fa0d75bc1a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:04<00:00, 204.90it/s]\n",
            "<ipython-input-6-8e26411ae407>:36: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  X_train = np.array([self.X_train[idx] for idx in train_idx])\n",
            "<ipython-input-6-8e26411ae407>:37: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  y_train = np.array([self.y_train[idx] for idx in train_idx])\n",
            "100%|██████████| 1000/1000 [00:02<00:00, 409.22it/s]\n",
            "<ipython-input-6-8e26411ae407>:40: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  X_valid = np.array([self.X_valid[idx] for idx in valid_idx])\n",
            "<ipython-input-6-8e26411ae407>:41: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  y_valid = np.array([self.y_valid[idx] for idx in valid_idx])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "#Original MNIST dataset\n",
        "print(f'Original training data size: {len(train_images)}')\n",
        "print(f'Original validation data size: {len(valid_images)}\\n')\n",
        "\n",
        "#Collaborator one's data\n",
        "print(f'Collaborator one\\'s training data size: {len(collaborator_models[0].data_loader.X_train)}')\n",
        "print(f'Collaborator one\\'s validation data size: {len(collaborator_models[0].data_loader.X_valid)}\\n')\n",
        "\n",
        "#Collaborator two's data\n",
        "print(f'Collaborator two\\'s training data size: {len(collaborator_models[1].data_loader.X_train)}')\n",
        "print(f'Collaborator two\\'s validation data size: {len(collaborator_models[1].data_loader.X_valid)}\\n')\n",
        "\n",
        "#Collaborator three's data\n",
        "#print(f'Collaborator three\\'s training data size: {len(collaborator_models[2].data_loader.X_train)}')\n",
        "#print(f'Collaborator three\\'s validation data size: {len(collaborator_models[2].data_loader.X_valid)}')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ndh6tr6adxOB",
        "outputId": "dabdfa4e-2a65-4e99-9809-14a00b676996"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original training data size: 42000\n",
            "Original validation data size: 18000\n",
            "\n",
            "Collaborator one's training data size: 86\n",
            "Collaborator one's validation data size: 10\n",
            "\n",
            "Collaborator two's training data size: 12\n",
            "Collaborator two's validation data size: 10\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Get the current values of the plan. Each of these can be overridden\n",
        "import json\n",
        "print(json.dumps(fx.get_plan(), indent=4, sort_keys=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FGKkV3zud5q6",
        "outputId": "60542d97-b21d-46f1-d82f-fcafa017908a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"{\\n    \\\"aggregator.settings.best_state_path\\\": \\\"save/keras_cnn_mnist_best.pbuf\\\",\\n    \\\"aggregator.settings.db_store_rounds\\\": 2,\\n    \\\"aggregator.settings.init_state_path\\\": \\\"save/keras_cnn_mnist_init.pbuf\\\",\\n    \\\"aggregator.settings.last_state_path\\\": \\\"save/keras_cnn_mnist_last.pbuf\\\",\\n    \\\"aggregator.settings.rounds_to_train\\\": 10,\\n    \\\"aggregator.settings.write_logs\\\": true,\\n    \\\"aggregator.template\\\": \\\"openfl.component.Aggregator\\\",\\n    \\\"assigner.settings.task_groups.0.name\\\": \\\"train_and_validate\\\",\\n    \\\"assigner.settings.task_groups.0.percentage\\\": 1.0,\\n    \\\"assigner.settings.task_groups.0.tasks.0\\\": \\\"aggregated_model_validation\\\",\\n    \\\"assigner.settings.task_groups.0.tasks.1\\\": \\\"train\\\",\\n    \\\"assigner.settings.task_groups.0.tasks.2\\\": \\\"locally_tuned_model_validation\\\",\\n    \\\"assigner.template\\\": \\\"openfl.component.RandomGroupedAssigner\\\",\\n    \\\"collaborator.settings.db_store_rounds\\\": 1,\\n    \\\"collaborator.settings.delta_updates\\\": false,\\n    \\\"collaborator.settings.opt_treatment\\\": \\\"RESET\\\",\\n    \\\"collaborator.template\\\": \\\"openfl.component.Collaborator\\\",\\n    \\\"compression_pipeline.settings\\\": {},\\n    \\\"compression_pipeline.template\\\": \\\"openfl.pipelines.NoCompressionPipeline\\\",\\n    \\\"data_loader.settings.batch_size\\\": 256,\\n    \\\"data_loader.settings.collaborator_count\\\": 2,\\n    \\\"data_loader.settings.data_group_name\\\": \\\"mnist\\\",\\n    \\\"data_loader.template\\\": \\\"src.tfmnist_inmemory.TensorFlowMNISTInMemory\\\",\\n    \\\"network.settings.agg_addr\\\": \\\"e2498b5a2b64\\\",\\n    \\\"network.settings.agg_port\\\": 58300,\\n    \\\"network.settings.cert_folder\\\": \\\"cert\\\",\\n    \\\"network.settings.client_reconnect_interval\\\": 5,\\n    \\\"network.settings.disable_client_auth\\\": false,\\n    \\\"network.settings.hash_salt\\\": \\\"auto\\\",\\n    \\\"network.settings.tls\\\": true,\\n    \\\"network.template\\\": \\\"openfl.federation.Network\\\",\\n    \\\"task_runner.settings\\\": {},\\n    \\\"task_runner.template\\\": \\\"src.keras_cnn.KerasCNN\\\",\\n    \\\"tasks.aggregated_model_validation.function\\\": \\\"validate\\\",\\n    \\\"tasks.aggregated_model_validation.kwargs.apply\\\": \\\"global\\\",\\n    \\\"tasks.aggregated_model_validation.kwargs.batch_size\\\": 32,\\n    \\\"tasks.aggregated_model_validation.kwargs.metrics.0\\\": \\\"accuracy\\\",\\n    \\\"tasks.locally_tuned_model_validation.function\\\": \\\"validate\\\",\\n    \\\"tasks.locally_tuned_model_validation.kwargs.apply\\\": \\\"local\\\",\\n    \\\"tasks.locally_tuned_model_validation.kwargs.batch_size\\\": 32,\\n    \\\"tasks.locally_tuned_model_validation.kwargs.metrics.0\\\": \\\"accuracy\\\",\\n    \\\"tasks.settings\\\": {},\\n    \\\"tasks.train.function\\\": \\\"train\\\",\\n    \\\"tasks.train.kwargs.batch_size\\\": 32,\\n    \\\"tasks.train.kwargs.epochs\\\": 1,\\n    \\\"tasks.train.kwargs.metrics.0\\\": \\\"loss\\\"\\n}\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Run experiment, return trained FederatedModel\n",
        "final_fl_model = fx.run_experiment(collaborators,override_config={'aggregator.settings.rounds_to_train':5, 'collaborator.settings.opt_treatment': 'CONTINUE_GLOBAL'})\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "arLFeLzveKpY",
        "outputId": "c023c464-4b14-4915-8b9a-e325e6f75bc4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/tensorflow/python/data/ops/dataset_ops.py:4526: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 533ms/step - loss: 2.4400 - accuracy: 0.0000e+00\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 1.7422 - accuracy: 0.5000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 1.6634 - accuracy: 0.5000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2.1443 - accuracy: 0.3000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 2.1568 - accuracy: 0.1667\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 1.6597 - accuracy: 0.4000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 2.2125 - accuracy: 0.2727\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 2.6924 - accuracy: 0.2941\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 1.7693 - accuracy: 0.4545\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 2.8446 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 3.0471 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.2571 - accuracy: 0.0769\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2.4301 - accuracy: 0.0000e+00\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 2.4975 - accuracy: 0.0377\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 1.4563 - accuracy: 0.5000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.2005 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 2.1641 - accuracy: 0.1333\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 1.6203 - accuracy: 0.4286\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 2.0908 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 2.1212 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 1.6466 - accuracy: 0.5000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 2.5688 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.6245 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 1.9837 - accuracy: 0.4000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 2.7312 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2.9407 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2.0419 - accuracy: 0.0909\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.5615 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 2.6097 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 1.9932 - accuracy: 0.3000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2.1656 - accuracy: 0.0000e+00\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 2.3075 - accuracy: 0.0976\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 1.1609 - accuracy: 0.9000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 2.0731 - accuracy: 0.3043\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 2.0323 - accuracy: 0.3091\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 1.1553 - accuracy: 0.6087\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2.3011 - accuracy: 0.4000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 2.0635 - accuracy: 0.5000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 1.9387 - accuracy: 0.5000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 3.0775 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 2.9363 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2.3954 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 2.5421 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 2.7666 - accuracy: 0.0769\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 1.9614 - accuracy: 0.3000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 2.1526 - accuracy: 0.1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 2.4135 - accuracy: 0.0526\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 1.6043 - accuracy: 0.6000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2.2406 - accuracy: 0.0000e+00\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 1.3138 - accuracy: 0.5544\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.7773 - accuracy: 0.7333\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 2.6041 - accuracy: 0.1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 2.5994 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 2.0010 - accuracy: 0.3000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 2.8497 - accuracy: 0.0000e+00\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 2.0976 - accuracy: 0.3636\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 1.9416 - accuracy: 0.5000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 2.3784 - accuracy: 0.0000e+00\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 1.2511 - accuracy: 0.6392\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 1.1144 - accuracy: 0.5000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.2494 - accuracy: 0.0000e+00\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 1.5851 - accuracy: 0.5545\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 1.9720 - accuracy: 0.4167\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 2.1195 - accuracy: 0.2941\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.2644 - accuracy: 0.2258\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 1.5851 - accuracy: 0.4706\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 2.2824 - accuracy: 0.4167\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 2.3969 - accuracy: 0.3636\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 1.8898 - accuracy: 0.5000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 3.0529 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 3.1056 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 2.3152 - accuracy: 0.0714\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 2.6707 - accuracy: 0.0833\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 2.7522 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.0202 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 2.3236 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2.4124 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 1.7876 - accuracy: 0.4545\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 2.1674 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 2.3531 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 1.6245 - accuracy: 0.5455\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 2.6238 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 2.7004 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.0330 - accuracy: 0.2000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 3.0523 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 2.6400 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.3356 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2.5272 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.4824 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 1.9753 - accuracy: 0.1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 2.6564 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 2.4706 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2.0881 - accuracy: 0.3000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 1.9468 - accuracy: 0.3500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 2.2327 - accuracy: 0.2941\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 1.5094 - accuracy: 0.5000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 2.7214 - accuracy: 0.1875\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 1.9447 - accuracy: 0.6000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 2.5021 - accuracy: 0.3125\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 3.0480 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 2.8772 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2.3604 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2.4723 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 2.6151 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 1.8895 - accuracy: 0.3000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 2.3432 - accuracy: 0.0588\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 2.5471 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 1.9307 - accuracy: 0.2941\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 2.2102 - accuracy: 0.0000e+00\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 2.1792 - accuracy: 0.0882\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 1.4525 - accuracy: 0.5000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2.5413 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 2.2600 - accuracy: 0.0333\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.0276 - accuracy: 0.4545\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 2.8897 - accuracy: 0.0000e+00\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 2.7131 - accuracy: 0.0488\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 1.3629 - accuracy: 0.8000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 2.7329 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 2.5534 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 2.1310 - accuracy: 0.2000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 2.7894 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 2.6839 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2.1199 - accuracy: 0.0714\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 2.0047 - accuracy: 0.3750\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 2.2230 - accuracy: 0.2353\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 1.6909 - accuracy: 0.1250\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 2.1656 - accuracy: 0.5385\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 2.3943 - accuracy: 0.3077\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 1.7354 - accuracy: 0.6154\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 3.0232 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 2.9995 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.4142 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 2.5351 - accuracy: 0.0909\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 2.4625 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 1.9744 - accuracy: 0.2727\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 2.1199 - accuracy: 0.1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 2.3272 - accuracy: 0.0526\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 1.5972 - accuracy: 0.6000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.2925 - accuracy: 0.0000e+00\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 2.0783 - accuracy: 0.2000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 1.5550 - accuracy: 0.5000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 2.3600 - accuracy: 0.0833\n",
            "11/11 [==============================] - 0s 16ms/step - loss: 0.4965 - accuracy: 0.8957\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 1.7785 - accuracy: 0.5833\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 2.7335 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 2.7607 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 2.0580 - accuracy: 0.1818\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 2.5829 - accuracy: 0.0588\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 2.7659 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 2.0101 - accuracy: 0.2941\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 2.6434 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 2.6494 - accuracy: 0.0000e+00\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 1.7522 - accuracy: 0.6410\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.1979 - accuracy: 0.4000\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 2.0100 - accuracy: 0.3000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 1.4002 - accuracy: 0.2000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2.5393 - accuracy: 0.1667\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 2.0868 - accuracy: 0.4000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2.0994 - accuracy: 0.4167\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 2.9892 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 3.0411 - accuracy: 0.0000e+00\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 2.0397 - accuracy: 0.2245\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 2.5633 - accuracy: 0.1429\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 1.8620 - accuracy: 0.4068\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 2.3196 - accuracy: 0.3571\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2.1884 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 2.2573 - accuracy: 0.0667\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 1.6976 - accuracy: 0.4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 2.3039 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2.2080 - accuracy: 0.0588\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 1.7869 - accuracy: 0.3000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2.6427 - accuracy: 0.0000e+00\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 1.1073 - accuracy: 0.7273\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 1.7071 - accuracy: 0.5833\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 2.9663 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 2.9556 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.3250 - accuracy: 0.1000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.6340 - accuracy: 0.0000e+00\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 2.2482 - accuracy: 0.2000\n",
            "1/1 [==============================] - 0s 112ms/step - loss: 2.2754 - accuracy: 0.3333\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.5692 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 2.3879 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 1.9388 - accuracy: 0.1667\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.2546 - accuracy: 0.2000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 2.3010 - accuracy: 0.1935\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 1.7438 - accuracy: 0.4000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 2.5956 - accuracy: 0.1200\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.6681 - accuracy: 0.1613\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 1.8993 - accuracy: 0.1600\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 3.1486 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 2.9506 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.5092 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 2.6448 - accuracy: 0.1000\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 2.0922 - accuracy: 0.3125\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 1.7885 - accuracy: 0.4000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2.3212 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 2.2842 - accuracy: 0.0741\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 1.8065 - accuracy: 0.6000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2.2460 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 2.2159 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 1.6560 - accuracy: 0.4000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 2.3260 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 2.5546 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 1.7487 - accuracy: 0.4167\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2.8499 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 2.7896 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2.1859 - accuracy: 0.0714\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.6232 - accuracy: 0.0000e+00\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 2.6555 - accuracy: 0.0303\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 1.9317 - accuracy: 0.4167\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.5187 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2.5452 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 1.8971 - accuracy: 0.2727\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 1.7445 - accuracy: 0.6604\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 1.9050 - accuracy: 0.5238\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 1.1944 - accuracy: 0.9057\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.4807 - accuracy: 0.1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 1.1856 - accuracy: 0.8125\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 1.9557 - accuracy: 0.5000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 3.0729 - accuracy: 0.0000e+00\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 2.2311 - accuracy: 0.3026\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2.7955 - accuracy: 0.1786\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 2.7519 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 2.9464 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2.1131 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2.1998 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 2.4678 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 1.6426 - accuracy: 0.5000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2.2677 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 2.3850 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 1.6952 - accuracy: 0.3000\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 2.6871 - accuracy: 0.0536\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 2.6580 - accuracy: 0.0909\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 2.1093 - accuracy: 0.1786\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2.9069 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 2.7657 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 2.2180 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 2.4520 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2.5321 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 1.9065 - accuracy: 0.3000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 2.5991 - accuracy: 0.0000e+00\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 2.0654 - accuracy: 0.2258\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 1.6032 - accuracy: 0.5833\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 2.3514 - accuracy: 0.1803\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 2.1208 - accuracy: 0.2353\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 1.8022 - accuracy: 0.1967\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 1.7508 - accuracy: 0.5455\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 2.3076 - accuracy: 0.2273\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 1.4170 - accuracy: 0.8364\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 3.0663 - accuracy: 0.0000e+00\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 2.3741 - accuracy: 0.1528\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 1.8449 - accuracy: 0.5000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2.5008 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 2.6396 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 1.9633 - accuracy: 0.3000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 2.3572 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 2.3242 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 1.8311 - accuracy: 0.3000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 2.1726 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 2.3604 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 1.6429 - accuracy: 0.5000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2.6802 - accuracy: 0.0000e+00\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.7937 - accuracy: 0.3913\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 1.0258 - accuracy: 0.6923\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.9392 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 2.8572 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2.1858 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 2.3272 - accuracy: 0.0909\n",
            "19/19 [==============================] - 0s 17ms/step - loss: 0.4088 - accuracy: 0.9192\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.4090 - accuracy: 0.4545\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.4376 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 2.3153 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 1.8182 - accuracy: 0.4000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2.0909 - accuracy: 0.3000\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 0.7660 - accuracy: 0.7615\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.7712 - accuracy: 0.6000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 2.1298 - accuracy: 0.3529\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 1.3453 - accuracy: 0.7361\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 1.6133 - accuracy: 0.6471\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 2.9844 - accuracy: 0.0000e+00\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 2.6504 - accuracy: 0.1250\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 1.8958 - accuracy: 0.5000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 2.4275 - accuracy: 0.1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 2.5471 - accuracy: 0.0833\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 1.8804 - accuracy: 0.3000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 2.4154 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 2.3396 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 1.8624 - accuracy: 0.3636\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2.1821 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 2.2935 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 1.6575 - accuracy: 0.6000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2.4342 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.6182 - accuracy: 0.0625\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 1.8886 - accuracy: 0.1364\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2.8235 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 2.8472 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.1406 - accuracy: 0.1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 2.4409 - accuracy: 0.0833\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 2.6002 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 1.8902 - accuracy: 0.1667\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2.5186 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 2.4926 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 1.8965 - accuracy: 0.4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 2.2203 - accuracy: 0.1429\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 1.8651 - accuracy: 0.5263\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 2.0395 - accuracy: 0.1786\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 2.8666 - accuracy: 0.0580\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 1.8913 - accuracy: 0.5000\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.7826 - accuracy: 0.1014\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 3.0180 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 3.0703 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 2.2888 - accuracy: 0.0625\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2.6031 - accuracy: 0.1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 2.5321 - accuracy: 0.0556\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.1134 - accuracy: 0.3000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 2.3345 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2.2867 - accuracy: 0.0833\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 1.8687 - accuracy: 0.1818\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2.3190 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 2.2927 - accuracy: 0.1429\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 1.7595 - accuracy: 0.3333\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 2.8425 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 2.5386 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.2457 - accuracy: 0.1818\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 2.9174 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2.7939 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 2.2583 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 2.3912 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 2.7025 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 1.8671 - accuracy: 0.4286\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2.4052 - accuracy: 0.0000e+00\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 2.3371 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 1.4805 - accuracy: 0.5000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 2.1092 - accuracy: 0.3571\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2.0743 - accuracy: 0.2143\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 1.6863 - accuracy: 0.3571\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 2.8287 - accuracy: 0.1667\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 2.5917 - accuracy: 0.3636\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.2889 - accuracy: 0.2083\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 3.1078 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 2.9507 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.4109 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 2.5914 - accuracy: 0.0909\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 2.6398 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2.0220 - accuracy: 0.2727\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2.2055 - accuracy: 0.1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 2.2638 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 1.7034 - accuracy: 0.5000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 2.1975 - accuracy: 0.1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 1.4183 - accuracy: 0.6300\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 1.3756 - accuracy: 0.5000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 2.5992 - accuracy: 0.0833\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 2.1715 - accuracy: 0.2262\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 1.1876 - accuracy: 0.5833\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2.7382 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 2.8261 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 2.0853 - accuracy: 0.3000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2.7165 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 2.4501 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2.0280 - accuracy: 0.2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2.4614 - accuracy: 0.0000e+00\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.9438 - accuracy: 0.7982\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.2735 - accuracy: 0.3846\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 2.1491 - accuracy: 0.4000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 1.9566 - accuracy: 0.3846\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 1.7136 - accuracy: 0.4000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 2.3187 - accuracy: 0.3333\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2.3418 - accuracy: 0.3333\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 1.9038 - accuracy: 0.5000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 3.1386 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 3.0800 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 2.5104 - accuracy: 0.0400\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 2.5972 - accuracy: 0.1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 2.4801 - accuracy: 0.1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 2.0242 - accuracy: 0.1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2.2871 - accuracy: 0.0909\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 1.8191 - accuracy: 0.3867\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 1.4046 - accuracy: 0.4545\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2.2239 - accuracy: 0.1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.1142 - accuracy: 0.1053\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 1.7091 - accuracy: 0.3000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2.5367 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 2.3526 - accuracy: 0.0833\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 1.9232 - accuracy: 0.5000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2.9202 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 2.8644 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2.2432 - accuracy: 0.1667\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.4838 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 2.5450 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 1.9222 - accuracy: 0.1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2.5545 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 2.6522 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 1.9210 - accuracy: 0.3000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 2.1575 - accuracy: 0.2727\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 2.3300 - accuracy: 0.1333\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 1.5879 - accuracy: 0.2727\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.5588 - accuracy: 0.2000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 1.8029 - accuracy: 0.4194\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 1.1215 - accuracy: 0.6667\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 3.1466 - accuracy: 0.0000e+00\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 1.2720 - accuracy: 0.7174\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2.3069 - accuracy: 0.4667\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 2.4438 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 2.9013 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 1.9070 - accuracy: 0.3077\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2.3019 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 2.2366 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 1.7772 - accuracy: 0.1538\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 2.1304 - accuracy: 0.0667\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 2.2165 - accuracy: 0.0323\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 1.7393 - accuracy: 0.3333\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2.4253 - accuracy: 0.1176\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 2.6053 - accuracy: 0.0769\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 1.8154 - accuracy: 0.4706\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2.7775 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 2.7323 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2.1125 - accuracy: 0.1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 2.7198 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 2.5411 - accuracy: 0.0000e+00\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 2.0180 - accuracy: 0.0894\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 2.6310 - accuracy: 0.0000e+00\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 2.0794 - accuracy: 0.2931\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 1.8189 - accuracy: 0.5000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2.0410 - accuracy: 0.3636\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 1.9879 - accuracy: 0.3125\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 1.6347 - accuracy: 0.5455\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 2.3830 - accuracy: 0.3846\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2.4339 - accuracy: 0.1538\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 1.8880 - accuracy: 0.4615\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 2.9995 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 3.0544 - accuracy: 0.0000e+00\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 2.2212 - accuracy: 0.0270\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.5000 - accuracy: 0.1429\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 2.7006 - accuracy: 0.0500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 1.3459 - accuracy: 0.6429\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 2.2796 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 2.2665 - accuracy: 0.0333\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 1.8432 - accuracy: 0.3750\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2.1584 - accuracy: 0.0400\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 2.2454 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 1.6110 - accuracy: 0.4800\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 2.6407 - accuracy: 0.0000e+00\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 2.5780 - accuracy: 0.1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 1.6942 - accuracy: 0.4000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.7075 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 2.8472 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 2.0662 - accuracy: 0.2000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 2.6048 - accuracy: 0.0000e+00\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 1.9493 - accuracy: 0.2522\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 1.1149 - accuracy: 0.6154\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 2.4811 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 2.4944 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 1.8410 - accuracy: 0.4167\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2.2575 - accuracy: 0.2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 2.1481 - accuracy: 0.3000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 1.7349 - accuracy: 0.2500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 2.0437 - accuracy: 0.5455\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 2.4707 - accuracy: 0.2308\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 1.6044 - accuracy: 0.5455\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 3.0689 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 2.9480 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 2.3289 - accuracy: 0.0833\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 2.6664 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 2.5239 - accuracy: 0.1333\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2.0891 - accuracy: 0.3000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2.1278 - accuracy: 0.0909\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 2.2808 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 1.6358 - accuracy: 0.4545\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 2.3465 - accuracy: 0.0049\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 2.4270 - accuracy: 0.0000e+00\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 1.3933 - accuracy: 0.8293\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 2.6204 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 2.3069 - accuracy: 0.1500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2.0471 - accuracy: 0.4000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2.8873 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 3.0260 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2.1882 - accuracy: 0.1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 2.5302 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 2.7142 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 1.9275 - accuracy: 0.1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 2.5629 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 2.5931 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 1.6088 - accuracy: 0.7500\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 2.2547 - accuracy: 0.0909\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 1.9500 - accuracy: 0.3750\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 1.8237 - accuracy: 0.4545\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 2.7776 - accuracy: 0.1765\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 1.9773 - accuracy: 0.2222\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 2.5221 - accuracy: 0.2353\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 2.8991 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 2.9284 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.2256 - accuracy: 0.0833\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 2.5662 - accuracy: 0.2000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 2.6866 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 1.9845 - accuracy: 0.3000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 2.3120 - accuracy: 0.0455\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 1.5303 - accuracy: 0.5851\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.9450 - accuracy: 0.7727\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2.2246 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 2.1548 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 1.5609 - accuracy: 0.6667\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 2.5650 - accuracy: 0.2000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2.7384 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 1.9401 - accuracy: 0.4000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 2.6681 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 2.9901 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 1.9753 - accuracy: 0.2000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 2.5204 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 2.8862 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 1.9731 - accuracy: 0.2105\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 2.5028 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 2.4548 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2.0047 - accuracy: 0.3103\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2.0706 - accuracy: 0.3000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 1.9703 - accuracy: 0.2667\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 1.6731 - accuracy: 0.5000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2.4812 - accuracy: 0.3000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 2.5662 - accuracy: 0.1765\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 1.9723 - accuracy: 0.3000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 3.0002 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 2.9614 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2.3366 - accuracy: 0.0909\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 2.6417 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2.4156 - accuracy: 0.0769\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 2.2634 - accuracy: 0.2941\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 2.2293 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 2.3320 - accuracy: 0.0588\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 1.7412 - accuracy: 0.5000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 2.1805 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 2.2631 - accuracy: 0.0385\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 1.6770 - accuracy: 0.5000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 2.6796 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 2.6185 - accuracy: 0.0909\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2.0412 - accuracy: 0.4000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2.6660 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 2.9648 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 1.9526 - accuracy: 0.3077\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 2.4842 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 2.5425 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 1.9107 - accuracy: 0.5000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2.4327 - accuracy: 0.0000e+00\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 2.4149 - accuracy: 0.0571\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 1.8905 - accuracy: 0.4545\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 2.1577 - accuracy: 0.1818\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 1.4841 - accuracy: 0.6263\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 1.3452 - accuracy: 0.5455\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 2.3385 - accuracy: 0.3000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 2.2434 - accuracy: 0.3000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 1.9340 - accuracy: 0.5000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2.9443 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 3.0640 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2.2569 - accuracy: 0.0909\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2.8592 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 2.2365 - accuracy: 0.1667\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2.4492 - accuracy: 0.0588\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2.2045 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 2.0747 - accuracy: 0.2692\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 1.7077 - accuracy: 0.4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 2.0280 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 2.3951 - accuracy: 0.0370\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 1.4992 - accuracy: 0.5455\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 2.6851 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 2.4341 - accuracy: 0.0667\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 2.1183 - accuracy: 0.2917\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 2.8955 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2.7157 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 2.2848 - accuracy: 0.0588\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 2.4599 - accuracy: 0.0000e+00\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 2.4810 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 1.3537 - accuracy: 0.7273\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 2.4585 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2.6672 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 1.8895 - accuracy: 0.3889\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2.0409 - accuracy: 0.5000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 2.2051 - accuracy: 0.2174\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 1.6225 - accuracy: 0.3333\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.0472 - accuracy: 0.6154\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 2.2212 - accuracy: 0.1733\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 1.2989 - accuracy: 0.3846\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 3.1547 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 3.1135 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 2.4648 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.4247 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 2.6876 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 1.9459 - accuracy: 0.1429\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 2.4108 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 2.1255 - accuracy: 0.1538\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 1.8991 - accuracy: 0.2000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2099 - accuracy: 0.0000e+00\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 2.0298 - accuracy: 0.1622\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 1.5016 - accuracy: 0.5000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.8513 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2455 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.4046 - accuracy: 0.1852\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 2.6992 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 2.7326 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 2.0389 - accuracy: 0.1000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.6146 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 2.6365 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.0389 - accuracy: 0.1667\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.5967 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 2.5539 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 1.9323 - accuracy: 0.3846\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.1353 - accuracy: 0.2000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 2.1957 - accuracy: 0.1818\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 1.6568 - accuracy: 0.3000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.3987 - accuracy: 0.3333\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 2.3379 - accuracy: 0.2097\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 1.5449 - accuracy: 0.5333\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 3.0218 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 3.1929 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2.3021 - accuracy: 0.0769\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 2.4236 - accuracy: 0.1212\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.5776 - accuracy: 0.0000e+00\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 1.8902 - accuracy: 0.3939\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2.3883 - accuracy: 0.0000e+00\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 1.8519 - accuracy: 0.4032\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 1.6866 - accuracy: 0.5000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2.3141 - accuracy: 0.0000e+00\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 0.6782 - accuracy: 0.8556\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 1.7865 - accuracy: 0.5455\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2.6389 - accuracy: 0.0000e+00\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 2.5532 - accuracy: 0.1087\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 1.6549 - accuracy: 0.5000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.8270 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 2.7989 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2.0700 - accuracy: 0.2500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 2.7753 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 2.6437 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 1.9997 - accuracy: 0.3158\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 2.5266 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 2.4871 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 1.7799 - accuracy: 0.4375\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 2.3339 - accuracy: 0.1429\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 2.0110 - accuracy: 0.2353\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 1.8198 - accuracy: 0.1429\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.2059 - accuracy: 0.4286\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 2.2791 - accuracy: 0.2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 1.7885 - accuracy: 0.5714\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 3.1437 - accuracy: 0.0000e+00\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 1.5287 - accuracy: 0.5843\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 1.8459 - accuracy: 0.4167\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 2.6225 - accuracy: 0.1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 2.4258 - accuracy: 0.0769\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 1.7471 - accuracy: 0.4000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.3080 - accuracy: 0.1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.1441 - accuracy: 0.0526\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 1.8118 - accuracy: 0.3000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 2.4096 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 2.2862 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 1.8831 - accuracy: 0.3636\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2.6801 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 2.1883 - accuracy: 0.0833\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2.2493 - accuracy: 0.3571\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 2.8114 - accuracy: 0.0000e+00\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 2.6807 - accuracy: 0.0303\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 1.7468 - accuracy: 0.5455\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 2.8568 - accuracy: 0.0000e+00\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 1.4087 - accuracy: 0.6441\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 2.0550 - accuracy: 0.5000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2.5641 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 2.5903 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 1.9611 - accuracy: 0.3636\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 2.0774 - accuracy: 0.3000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 1.9987 - accuracy: 0.3571\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 1.6638 - accuracy: 0.5000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 2.3771 - accuracy: 0.2000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 1.9026 - accuracy: 0.4643\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2.0396 - accuracy: 0.5000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 3.0337 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 3.1471 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 2.2792 - accuracy: 0.0500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2.6070 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 2.6355 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.0309 - accuracy: 0.3333\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 2.5713 - accuracy: 0.0000e+00\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 1.9329 - accuracy: 0.2128\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 1.8392 - accuracy: 0.4167\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2.4538 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 2.1007 - accuracy: 0.0769\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 1.9048 - accuracy: 0.2000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 2.6540 - accuracy: 0.0000e+00\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 1.6304 - accuracy: 0.5344\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 1.3998 - accuracy: 0.5000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 2.7754 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 2.7030 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 2.1476 - accuracy: 0.1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 2.8181 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 2.5786 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2.2175 - accuracy: 0.1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 2.3808 - accuracy: 0.0000e+00\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 2.1655 - accuracy: 0.2766\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 1.3240 - accuracy: 0.5833\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 1.9226 - accuracy: 0.4000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 1.9464 - accuracy: 0.3962\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 1.4070 - accuracy: 0.5000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 2.0207 - accuracy: 0.4000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 2.1601 - accuracy: 0.4737\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 1.6245 - accuracy: 0.6667\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 2.9795 - accuracy: 0.0000e+00\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 2.9658 - accuracy: 0.0556\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 1.7144 - accuracy: 0.6190\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 2.3571 - accuracy: 0.0800\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 2.5635 - accuracy: 0.0526\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 1.9319 - accuracy: 0.3200\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 2.2254 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 2.3420 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 1.7385 - accuracy: 0.2727\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 2.1021 - accuracy: 0.0263\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 2.2008 - accuracy: 0.0571\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 1.4499 - accuracy: 0.7488\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 2.4764 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 2.7596 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 1.8657 - accuracy: 0.2727\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2.8103 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 3.0030 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2.1117 - accuracy: 0.1333\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 2.6030 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2.6554 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 1.9613 - accuracy: 0.2941\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2.4211 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 2.6587 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 1.7861 - accuracy: 0.4000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 1.8443 - accuracy: 0.3529\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 1.9433 - accuracy: 0.5000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 1.4550 - accuracy: 0.6471\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 2.2468 - accuracy: 0.2727\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 2.0943 - accuracy: 0.3412\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 1.5605 - accuracy: 0.4545\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 3.0667 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 3.0138 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.3685 - accuracy: 0.1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 2.6352 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 2.3124 - accuracy: 0.2000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2.0771 - accuracy: 0.4000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2.1345 - accuracy: 0.0417\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 2.3532 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 1.6305 - accuracy: 0.5000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 2.1246 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 2.2812 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 1.5119 - accuracy: 0.6818\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2.5066 - accuracy: 0.0000e+00\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 1.5130 - accuracy: 0.5794\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 1.5020 - accuracy: 0.5000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 2.7917 - accuracy: 0.0000e+00\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 1.6859 - accuracy: 0.5673\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 1.5947 - accuracy: 0.5833\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2.6788 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 2.4765 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 2.0828 - accuracy: 0.1250\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 2.5452 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 2.4998 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 1.8046 - accuracy: 0.3810\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 1.7762 - accuracy: 0.6053\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 2.0188 - accuracy: 0.4324\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 1.1584 - accuracy: 0.7895\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 1.8411 - accuracy: 0.5741\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2.2966 - accuracy: 0.4000\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 1.4926 - accuracy: 0.7593\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2.5825 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 3.1259 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 1.9195 - accuracy: 0.2727\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 2.6277 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 2.2842 - accuracy: 0.2000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 2.0545 - accuracy: 0.0714\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 2.2463 - accuracy: 0.1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 2.2966 - accuracy: 0.0714\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 1.7299 - accuracy: 0.5000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 2.1791 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 2.3223 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 1.8360 - accuracy: 0.2778\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2.4994 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 2.3372 - accuracy: 0.0714\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 1.9210 - accuracy: 0.4000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 2.7547 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 2.7933 - accuracy: 0.0000e+00\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 2.4358 - accuracy: 0.0091\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2.4166 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 2.6212 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 1.8560 - accuracy: 0.2727\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.3656 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 2.4528 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 1.7008 - accuracy: 0.5000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 1.8136 - accuracy: 0.2000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 2.0912 - accuracy: 0.3000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 1.4169 - accuracy: 0.4000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 2.0839 - accuracy: 0.4667\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 2.5218 - accuracy: 0.1538\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 1.6588 - accuracy: 0.6667\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.9984 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 3.0554 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.2909 - accuracy: 0.0476\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2.6587 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 2.3726 - accuracy: 0.0833\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 2.1277 - accuracy: 0.4000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.2843 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 2.1714 - accuracy: 0.1053\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 1.5777 - accuracy: 0.6562\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2.3647 - accuracy: 0.0000e+00\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 2.2112 - accuracy: 0.0513\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 1.3910 - accuracy: 0.7000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 2.6187 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 2.5738 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 2.0005 - accuracy: 0.0000e+00\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 3.0056 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 2.9297 - accuracy: 0.0000e+00\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 2.4353 - accuracy: 0.0175\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2.5720 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 2.6276 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 1.9963 - accuracy: 0.1875\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2.6270 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 2.5765 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 1.9345 - accuracy: 0.5000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.2552 - accuracy: 0.2000\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.9536 - accuracy: 0.8316\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 1.7606 - accuracy: 0.5000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2.4189 - accuracy: 0.4000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.4266 - accuracy: 0.2609\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 1.9549 - accuracy: 0.4000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 2.9093 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 2.9918 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 2.2149 - accuracy: 0.1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2.5899 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 2.5096 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2.0225 - accuracy: 0.3000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 2.3294 - accuracy: 0.0000e+00\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.2303 - accuracy: 0.9610\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2.1832 - accuracy: 0.5000\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 2.4104 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 2.1833 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 1.8324 - accuracy: 0.2000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.5402 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 2.4542 - accuracy: 0.0833\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 1.9481 - accuracy: 0.5000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2.8355 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.8362 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.1478 - accuracy: 0.1000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.5712 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 2.5128 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.0126 - accuracy: 0.2500\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 2.5324 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 2.5198 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 1.9065 - accuracy: 0.2000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 2.1698 - accuracy: 0.2000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2.3029 - accuracy: 0.0909\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 1.6693 - accuracy: 0.4000\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 1.8788 - accuracy: 0.5833\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 2.3311 - accuracy: 0.2727\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 1.4650 - accuracy: 0.8056\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 3.0623 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 2.9472 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2.3309 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 2.6452 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.2830 - accuracy: 0.0968\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.3078 - accuracy: 0.2667\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.0770 - accuracy: 0.1000\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 2.3933 - accuracy: 0.0571\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 1.2161 - accuracy: 0.7000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 2.1440 - accuracy: 0.0833\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 2.1125 - accuracy: 0.1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 1.6457 - accuracy: 0.4167\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 2.5574 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 2.5426 - accuracy: 0.1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 1.9545 - accuracy: 0.2727\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2.9172 - accuracy: 0.0000e+00\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 2.6878 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 1.6621 - accuracy: 0.5333\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2.8228 - accuracy: 0.0000e+00\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 2.1699 - accuracy: 0.2656\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 1.7758 - accuracy: 0.5455\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2.5144 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 2.5717 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 1.6501 - accuracy: 0.6111\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2.1812 - accuracy: 0.3077\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 2.0189 - accuracy: 0.4167\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 1.7394 - accuracy: 0.4615\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 2.3034 - accuracy: 0.3077\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 2.1689 - accuracy: 0.3571\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 1.9251 - accuracy: 0.4615\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 3.1217 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 3.0258 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 2.4083 - accuracy: 0.1538\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.5780 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 2.7302 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2.0015 - accuracy: 0.3000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2.4244 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 2.2708 - accuracy: 0.0909\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 1.8525 - accuracy: 0.2143\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 2.1472 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 2.2597 - accuracy: 0.0000e+00\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 1.6576 - accuracy: 0.3947\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2.4370 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 2.6515 - accuracy: 0.0714\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 1.8367 - accuracy: 0.1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 2.9169 - accuracy: 0.0000e+00\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 2.5423 - accuracy: 0.1569\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.3764 - accuracy: 0.7879\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 2.6952 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 2.5811 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.1167 - accuracy: 0.0833\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 2.5026 - accuracy: 0.0131\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 2.5069 - accuracy: 0.0000e+00\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 1.9857 - accuracy: 0.2620\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 2.1876 - accuracy: 0.3571\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 2.0040 - accuracy: 0.3000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 1.7258 - accuracy: 0.2857\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.4898 - accuracy: 0.1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 2.4131 - accuracy: 0.1818\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 2.0449 - accuracy: 0.5000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 2.9220 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 3.1805 - accuracy: 0.0000e+00\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 2.0908 - accuracy: 0.1154\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2.4259 - accuracy: 0.0909\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 2.8745 - accuracy: 0.0333\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 1.7903 - accuracy: 0.2727\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 2.1955 - accuracy: 0.0909\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2.1228 - accuracy: 0.0833\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 1.7089 - accuracy: 0.1818\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2.1754 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2.2269 - accuracy: 0.0833\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 1.6542 - accuracy: 0.4000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 2.5439 - accuracy: 0.0000e+00\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 1.3675 - accuracy: 0.6122\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 1.8387 - accuracy: 0.5000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 2.8711 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 2.8199 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2.2450 - accuracy: 0.0769\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2.7745 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2.5429 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 2.1927 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2.6799 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2.3924 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 2.0391 - accuracy: 0.2353\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2.0249 - accuracy: 0.4000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 1.9746 - accuracy: 0.4667\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 1.6456 - accuracy: 0.5000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 2.1068 - accuracy: 0.2857\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 2.4671 - accuracy: 0.3333\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 1.6677 - accuracy: 0.5714\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 3.1303 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 3.0791 - accuracy: 0.0000e+00\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 2.2384 - accuracy: 0.0577\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2.7051 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2.5852 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.1339 - accuracy: 0.2000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2.5874 - accuracy: 0.0000e+00\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 1.0605 - accuracy: 0.7736\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 1.9387 - accuracy: 0.5000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 2.2508 - accuracy: 0.2308\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 2.2999 - accuracy: 0.0833\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 1.7887 - accuracy: 0.3077\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2.5186 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 2.4026 - accuracy: 0.1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 1.9339 - accuracy: 0.3000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.8249 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.8514 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2.1194 - accuracy: 0.2000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 2.7588 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 2.6983 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2.1578 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 2.5543 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 2.6409 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 1.8568 - accuracy: 0.4286\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 2.1136 - accuracy: 0.3000\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.4274 - accuracy: 0.9659\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 2.5223 - accuracy: 0.5000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 2.0479 - accuracy: 0.5000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 2.2687 - accuracy: 0.4545\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 1.6444 - accuracy: 0.6818\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2.9404 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 3.0097 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 2.2187 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.9058 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.4059 - accuracy: 0.1250\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 2.2950 - accuracy: 0.0714\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2.2422 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 2.2375 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 1.7089 - accuracy: 0.5000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 2.2968 - accuracy: 0.1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 2.3274 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 1.7547 - accuracy: 0.2000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 2.3183 - accuracy: 0.0833\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 2.5685 - accuracy: 0.0500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 1.7900 - accuracy: 0.2500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 2.6202 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 2.7500 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 1.9852 - accuracy: 0.3333\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.5650 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 1s 864ms/step - loss: 2.5925 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 1.9745 - accuracy: 0.2000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2.5337 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 2.4669 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 1.8826 - accuracy: 0.4000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2.0188 - accuracy: 0.3750\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 2.3544 - accuracy: 0.0909\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 1.7179 - accuracy: 0.3750\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2.1821 - accuracy: 0.5000\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 2.6892 - accuracy: 0.1282\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 1.4064 - accuracy: 0.5000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 2.9657 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 3.0629 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2.2472 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2.6205 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 2.5647 - accuracy: 0.0833\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.0280 - accuracy: 0.2000\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 2.1819 - accuracy: 0.1000\n",
            "8/8 [==============================] - 0s 34ms/step - loss: 0.7657 - accuracy: 0.8292\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 1.6367 - accuracy: 0.5000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 2.1411 - accuracy: 0.0385\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 2.1670 - accuracy: 0.0476\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 1.3405 - accuracy: 0.8462\n",
            "1/1 [==============================] - 0s 131ms/step - loss: 2.2914 - accuracy: 0.0714\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.4194 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 1.7055 - accuracy: 0.5000\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 2.8085 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 2.7073 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.1567 - accuracy: 0.1000\n",
            "1/1 [==============================] - 0s 103ms/step - loss: 2.6380 - accuracy: 0.0323\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.5199 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 2.0702 - accuracy: 0.0968\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 2.5302 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.5862 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 1.8509 - accuracy: 0.4545\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 2.1272 - accuracy: 0.3333\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 2.1251 - accuracy: 0.3750\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 1.6947 - accuracy: 0.5000\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 2.9123 - accuracy: 0.0816\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 2.6328 - accuracy: 0.1765\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 2.0798 - accuracy: 0.1020\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 3.0342 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 2.9564 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 109ms/step - loss: 2.3551 - accuracy: 0.0625\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 2.9290 - accuracy: 0.0500\n",
            "1/1 [==============================] - 0s 132ms/step - loss: 2.3831 - accuracy: 0.0769\n",
            "1/1 [==============================] - 0s 186ms/step - loss: 2.4104 - accuracy: 0.1500\n",
            "1/1 [==============================] - 0s 171ms/step - loss: 2.3158 - accuracy: 0.0909\n",
            "5/5 [==============================] - 0s 72ms/step - loss: 1.3015 - accuracy: 0.6917\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 1.9001 - accuracy: 0.4545\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 2.3028 - accuracy: 0.0667\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 2.3518 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 1.7100 - accuracy: 0.6000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.7811 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 2.5402 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 2.1683 - accuracy: 0.2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2.6528 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 2.8348 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2.0013 - accuracy: 0.2000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 2.6354 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 2.5853 - accuracy: 0.0000e+00\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 2.0604 - accuracy: 0.0769\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.6841 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 2.3763 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 1.9689 - accuracy: 0.2727\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.2597 - accuracy: 0.1818\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 2.3538 - accuracy: 0.1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 1.6827 - accuracy: 0.1818\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2.7935 - accuracy: 0.1429\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2.4311 - accuracy: 0.2000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 2.2626 - accuracy: 0.1786\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2.9935 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 3.0259 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.3018 - accuracy: 0.1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 2.7452 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 2.7532 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 1.9910 - accuracy: 0.2857\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 2.2146 - accuracy: 0.0000e+00\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 1.9872 - accuracy: 0.3654\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 1.0431 - accuracy: 0.7619\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.3453 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 2.2199 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 1.7691 - accuracy: 0.3077\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 2.5773 - accuracy: 0.0000e+00\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 2.4522 - accuracy: 0.0476\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 1.5312 - accuracy: 0.6000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 2.7761 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 2.7419 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2.0876 - accuracy: 0.0909\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 2.6441 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 2.6149 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.0052 - accuracy: 0.2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2.5943 - accuracy: 0.0000e+00\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 2.3694 - accuracy: 0.0500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 1.4806 - accuracy: 0.6667\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 2.2509 - accuracy: 0.1667\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.7607 - accuracy: 0.8319\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 1.5746 - accuracy: 0.5833\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 2.2849 - accuracy: 0.4545\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 2.3159 - accuracy: 0.3636\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 1.8928 - accuracy: 0.4545\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 3.0444 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 2.8081 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 2.3241 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 2.4947 - accuracy: 0.2000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 2.4689 - accuracy: 0.0909\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 1.9299 - accuracy: 0.2000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.4956 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 2.1028 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 1.9574 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2.2231 - accuracy: 0.0000e+00\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 1.7317 - accuracy: 0.4474\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 1.3696 - accuracy: 0.5455\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2.4085 - accuracy: 0.1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 2.4768 - accuracy: 0.0952\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 1.8101 - accuracy: 0.5000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2.7529 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 2.9507 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 2.1041 - accuracy: 0.1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 2.5754 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 2.6074 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 2.0169 - accuracy: 0.1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 2.4655 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 2.5721 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 1.8597 - accuracy: 0.2632\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.2018 - accuracy: 0.1667\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 1.7161 - accuracy: 0.6875\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 1.9428 - accuracy: 0.4167\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2.5624 - accuracy: 0.3000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 1.2117 - accuracy: 0.8319\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 2.0910 - accuracy: 0.5000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 3.0094 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 2.8854 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2.2092 - accuracy: 0.0556\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 2.5619 - accuracy: 0.0909\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 2.6005 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 2.0127 - accuracy: 0.2727\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2.2979 - accuracy: 0.1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 2.1410 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 1.7374 - accuracy: 0.2000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 2.1788 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 2.3065 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 1.6722 - accuracy: 0.4000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 2.4827 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 2.8126 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 1.8148 - accuracy: 0.4167\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2.9620 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 2.9644 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2.2653 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2.6660 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 2.6534 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.1130 - accuracy: 0.0000e+00\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 2.5433 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 2.4964 - accuracy: 0.0000e+00\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 1.6908 - accuracy: 0.6842\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.2361 - accuracy: 0.2727\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 2.2118 - accuracy: 0.1905\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 1.6981 - accuracy: 0.3636\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2.3702 - accuracy: 0.2000\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 1.9353 - accuracy: 0.4605\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 1.3963 - accuracy: 0.5000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 3.1224 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 3.0074 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.4226 - accuracy: 0.0909\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 2.5013 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 2.6055 - accuracy: 0.0909\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 1.9697 - accuracy: 0.3000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 2.2551 - accuracy: 0.1429\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.3156 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 1.7805 - accuracy: 0.3571\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 1.9401 - accuracy: 0.2000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 2.0244 - accuracy: 0.0769\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 1.4623 - accuracy: 0.5000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 2.5395 - accuracy: 0.1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 2.5967 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 1.9479 - accuracy: 0.3000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 2.8336 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 2.8120 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 2.1557 - accuracy: 0.2000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2.6828 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 2.6102 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 2.1069 - accuracy: 0.0909\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2.6253 - accuracy: 0.0000e+00\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 0.6284 - accuracy: 0.8750\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 3.0869 - accuracy: 0.1724\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2.1959 - accuracy: 0.3846\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 1.8339 - accuracy: 0.5556\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 1.8985 - accuracy: 0.3846\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2.0335 - accuracy: 0.6429\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 1.9247 - accuracy: 0.6000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 1.4208 - accuracy: 0.6429\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 3.1374 - accuracy: 0.0000e+00\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 2.4456 - accuracy: 0.2059\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 1.9703 - accuracy: 0.5000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2.4786 - accuracy: 0.1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 2.3854 - accuracy: 0.2000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 1.9501 - accuracy: 0.2000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2.2619 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 2.3749 - accuracy: 0.0588\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 1.6681 - accuracy: 0.4375\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 2.3010 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 2.1126 - accuracy: 0.0000e+00\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 1.8855 - accuracy: 0.0698\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 2.4844 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 2.4167 - accuracy: 0.1200\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 1.8734 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 2.9010 - accuracy: 0.0000e+00\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 1.2025 - accuracy: 0.7065\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2.0222 - accuracy: 0.5000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2.7430 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 2.6000 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 2.0192 - accuracy: 0.1905\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 2.5932 - accuracy: 0.0000e+00\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 2.3041 - accuracy: 0.2093\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 1.6569 - accuracy: 0.5000\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 1.8248 - accuracy: 0.6061\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 1.8761 - accuracy: 0.4722\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 1.3205 - accuracy: 0.6061\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2.1417 - accuracy: 0.4615\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 2.3525 - accuracy: 0.2037\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 1.4408 - accuracy: 0.6154\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 3.0159 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 3.1525 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2.2766 - accuracy: 0.0769\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 2.3464 - accuracy: 0.1000\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 2.6115 - accuracy: 0.0789\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 1.5149 - accuracy: 0.5000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 2.2094 - accuracy: 0.1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 2.3079 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 1.6974 - accuracy: 0.5000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 2.3149 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 2.1439 - accuracy: 0.1667\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 1.7655 - accuracy: 0.0909\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.7616 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 2.3641 - accuracy: 0.0455\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2.1587 - accuracy: 0.1364\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 2.8355 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.8551 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.1904 - accuracy: 0.0833\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2.7508 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 2.6337 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 2.1950 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.5788 - accuracy: 0.0000e+00\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 1.4581 - accuracy: 0.6296\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 1.6852 - accuracy: 0.5000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.0188 - accuracy: 0.3000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 2.0524 - accuracy: 0.5000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 1.5537 - accuracy: 0.4000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2.1787 - accuracy: 0.2727\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 2.7749 - accuracy: 0.1034\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 1.7421 - accuracy: 0.5455\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 3.0595 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 3.1235 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 2.3508 - accuracy: 0.1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2.5881 - accuracy: 0.0833\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 2.5970 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 2.0185 - accuracy: 0.1667\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 2.2100 - accuracy: 0.0473\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.4266 - accuracy: 0.0455\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 1.7408 - accuracy: 0.4257\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 2.3959 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2.2883 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 1.8378 - accuracy: 0.2000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 2.4435 - accuracy: 0.0000e+00\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 1.0818 - accuracy: 0.7200\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 2.3709 - accuracy: 0.3846\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 2.8195 - accuracy: 0.0000e+00\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 1.6255 - accuracy: 0.5905\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 1.9549 - accuracy: 0.4545\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.6280 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 2.5000 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 1.9841 - accuracy: 0.2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 2.4848 - accuracy: 0.0000e+00\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 2.1722 - accuracy: 0.1515\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 1.0937 - accuracy: 0.9091\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 1.9997 - accuracy: 0.3636\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 2.3841 - accuracy: 0.1765\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 1.4674 - accuracy: 0.5455\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2.4816 - accuracy: 0.2857\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 1.8527 - accuracy: 0.6538\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 2.2822 - accuracy: 0.3571\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 3.1718 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 3.1006 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.4908 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 2.7190 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 2.7609 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 2.0936 - accuracy: 0.1364\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2.3341 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 2.0560 - accuracy: 0.1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 1.8277 - accuracy: 0.2609\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2.3125 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 2.1583 - accuracy: 0.0833\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 1.8009 - accuracy: 0.4000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2.7548 - accuracy: 0.1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 2.4018 - accuracy: 0.1429\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 2.1771 - accuracy: 0.5000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 2.9819 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2.8997 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2.3000 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 2.6201 - accuracy: 0.0000e+00\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 1.5568 - accuracy: 0.5849\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 1.8945 - accuracy: 0.5000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 2.4325 - accuracy: 0.0000e+00\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 1.9669 - accuracy: 0.3827\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 1.0733 - accuracy: 0.8182\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.1714 - accuracy: 0.3636\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 1.7868 - accuracy: 0.5789\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 1.7973 - accuracy: 0.5455\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2.1343 - accuracy: 0.5714\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 1.3306 - accuracy: 0.7606\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 1.6230 - accuracy: 0.5714\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2.9684 - accuracy: 0.0000e+00\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.9744 - accuracy: 0.7562\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2.4060 - accuracy: 0.4545\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2.4560 - accuracy: 0.1176\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 2.7618 - accuracy: 0.0455\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2.0807 - accuracy: 0.1176\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2.4316 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 2.2942 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 1.9167 - accuracy: 0.3000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2.2171 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.2026 - accuracy: 0.0938\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 1.6338 - accuracy: 0.4167\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2.3733 - accuracy: 0.0000e+00\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 1.9520 - accuracy: 0.2979\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 1.6925 - accuracy: 0.5000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 3.0277 - accuracy: 0.0000e+00\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 2.2415 - accuracy: 0.2097\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2.0495 - accuracy: 0.5000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 2.6350 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 2.6941 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 2.0258 - accuracy: 0.2222\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 2.5474 - accuracy: 0.0000e+00\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 1.9136 - accuracy: 0.4706\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 2.3025 - accuracy: 0.1316\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 1.9433 - accuracy: 0.5333\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 2.2623 - accuracy: 0.1613\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 1.5492 - accuracy: 0.5333\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.2559 - accuracy: 0.3333\n",
            "13/13 [==============================] - 0s 19ms/step - loss: 0.6422 - accuracy: 0.8617\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 2.5900 - accuracy: 0.3889\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 3.0186 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 2.9430 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 2.3106 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 2.7966 - accuracy: 0.0556\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2.6946 - accuracy: 0.1429\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 2.1599 - accuracy: 0.0556\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 2.3666 - accuracy: 0.0000e+00\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 1.7465 - accuracy: 0.4737\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 1.5656 - accuracy: 0.5000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2.3812 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 2.3877 - accuracy: 0.0714\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 1.8352 - accuracy: 0.3000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2.6803 - accuracy: 0.0000e+00\n",
            "17/17 [==============================] - 0s 17ms/step - loss: 0.3365 - accuracy: 0.9296\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2.6269 - accuracy: 0.4545\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2.9226 - accuracy: 0.0000e+00\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 2.6423 - accuracy: 0.0200\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 1.7698 - accuracy: 0.5000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2.8085 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 2.5922 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 2.3053 - accuracy: 0.0909\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 2.3767 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2.4526 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 1.7882 - accuracy: 0.5312\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2.0074 - accuracy: 0.2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 2.1764 - accuracy: 0.2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 1.5870 - accuracy: 0.5833\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 2.4491 - accuracy: 0.2500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Save final model and load into keras\n",
        "final_fl_model.save_native('final_model')\n",
        "model = tf.keras.models.load_model('./final_model')\n"
      ],
      "metadata": {
        "id": "k5OSIcc1faIa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Test the final model on our test set\n",
        "model.evaluate(test_images,test_labels)"
      ],
      "metadata": {
        "id": "6_ollCcufvKk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "plt.figure(figsize=(9,6), dpi=150)\n",
        "plt.title('Keras MNIST unbalanced split')\n",
        "plt.plot([0.07627802075538784, 0.07518334008473902, 0.09541350667830556, 0.13141966053564103, 0.15887578643299638], label='FedAvg')\n",
        "plt.plot([0.07627802075538784, 0.07518334008473902, 0.09541350667830556, 0.1314459763141349, 0.15887578643299638], linestyle='--', label='FedProx (mu=1e-2)')\n",
        "plt.plot([0.07627802075538784, 0.0751056043850258, 0.09555227747093886, 0.131649036151357, 0.15966261748969554], linestyle='--', label='FedProx (mu=1e-1)')\n",
        "plt.plot([0.07627802075538784, 0.07517912408802659, 0.09641592293512076, 0.13676991989742965, 0.1684917744528502], linestyle='--', label='FedProx (mu=1e1)')\n",
        "\n",
        "plt.legend()\n",
        "plt.xticks(range(5))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "x-XZRENIf1JS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}